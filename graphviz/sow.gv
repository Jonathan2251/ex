// dot -Tpng sow.gv -o sow.png
digraph G {

  rankdir=LR;

  label="客戶預的預選模型：BERT-large, DLRM, GPT2-XL, ResNet50";

  node [shape=doubleoctagon]; Pytorch,Tensorflow,ONNX;

  node [shape=box,style=filled,fillcolor=lightyellow]; 
    ONNC_FE [label="ONNC \nFrontend"]; ONNC_BE [label="ONNC \nBackend"];
    Calibrator [label="Calibration/\nQuantization"];
    ArchSimu [label="ArchSimu"];
    NPU [label="bit-true generator\nStage-4:\nNPU:\n確認bit-true generator的\n正確性。客戶的預選模型\n都能翻譯成單核NPU能\n夠直接執行的機器碼。"]; 
    PseudoRunTime [label="ONNC \nPseudo\n Run Time"];

  node [shape=box,style=filled,fillcolor=white];
    S5 [label="Stage-5:\n進行CPU與NPU\n的溝通。模擬器\n上，以layer-by-\nlayer與whole\n model的方式執\n行。模擬器可能\n是C model或者\nVirtual Platform\n之一(??)。"];
    //S5 [label="Stage-5:確認ONNC編譯器的正確性。\n客戶的預選模型都能翻譯成\nCPU與NPU能夠直接執行的library call，\n並且透過簡單的方式進行CPU與NPU的溝通。\n驗收方式是在能夠執行的模擬器上，\n以layer-by-layer與whole model的方式執行。\n模擬器可能是C model或者Virtual Platform之一。"];
    Check [label="Stage-6:\nDouble\n Check"]; Simulator [label="SystemC"];

  Pytorch -> ONNC_FE;
  Tensorflow -> ONNC_FE;
  ONNX -> ONNC_FE;
  ONNC_FE -> Calibrator; // stage 2
  Calibrator -> ONNC_BE [label="ONNC-IR"]; // stage 2
  Calibrator -> ArchSimu; // stage 2
  ONNC_BE -> "CPU/\nTVM" [label="Subgraph"]; // stage 2

  ONNC_BE -> NPU [label="Intrinsic &\nSubgraph"]; // stage 4

  "CPU/\nTVM" -> Simulator [label="bin"]; // stage 4
  NPU -> Simulator [label="bin"]; // stage 4
  "CPU/\nTVM" -> PseudoRunTime [label="bin"]; // stage 4
  NPU -> PseudoRunTime [label="bin"]; // stage 4

  Simulator -> Check; // stage 6
  PseudoRunTime -> Check; // stage 6

  "CPU/\nTVM" -> S5;
  "NPU" -> S5;

  Simulator -> ONNC_FE [label="Precision"]; // stage 7
}
